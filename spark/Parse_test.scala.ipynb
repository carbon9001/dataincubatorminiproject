{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val inputDir = \"./test/allPosts/part-00000.xml.gz\"\n",
    "\n",
    "val conf = new SparkConf();\n",
    "conf.setAppName(\"test\");\n",
    "conf.set(\"spark.driver.allowMultipleContexts\", \"true\");\n",
    "conf.setMaster(\"local[*]\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@5c7761f3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sc = new SparkContext(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "./test/allPosts/part-00000.xml.gz MapPartitionsRDD[1] at textFile at <console>:21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testdata = sc.textFile(inputDir,minPartitions=2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "20506"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<parent>\n",
      "  <row AcceptedAnswerId=\"15\" AnswerCount=\"5\" Body=\"&lt;p&gt;How should I elicit prior distributions from experts when fitting a Bayesian model?&lt;/p&gt;&#10;\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:12.510\" FavoriteCount=\"17\" Id=\"1\" LastActivityDate=\"2010-09-15T21:08:26.077\" OwnerUserId=\"8\" PostTypeId=\"1\" Score=\"26\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;\" Title=\"Eliciting priors from experts\" ViewCount=\"1457\" />\n",
      "  \n",
      "  <row AcceptedAnswerId=\"59\" AnswerCount=\"7\" Body=\"&lt;p&gt;In many different statistical methods there is an &quot;assumption of normality&quot;.  What is &quot;normality&quot; and how do I know if there is normality?&lt;/p&gt;&#10;\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:57.157\" FavoriteCount=\"9\" Id=\"2\" LastActivityDate=\"2012-11-12T09:21:54.993\" LastEditDate=\"2010-08-07T17:56:44.800\" LastEditorUserId=\"88\" OwnerUserId=\"24\" PostTypeId=\"1\" Score=\"25\" Tags=\"&lt;distributions&gt;&lt;normality&gt;\" Title=\"What is normality?\" ViewCount=\"9803\" />\n",
      "  \n",
      "  <row AcceptedAnswerId=\"5\" AnswerCount=\"19\" Body=\"&lt;p&gt;What are some valuable Statistical Analysis open source projects available right now?&lt;/p&gt;&#10;&#10;&lt;p&gt;Edit: as pointed out by Sharpie, valuable could mean helping you get things done faster or more cheaply.&lt;/p&gt;&#10;\" CommentCount=\"4\" CommunityOwnedDate=\"2010-07-19T19:13:28.577\" CreationDate=\"2010-07-19T19:13:28.577\" FavoriteCount=\"37\" Id=\"3\" LastActivityDate=\"2013-05-27T14:48:36.927\" LastEditDate=\"2011-02-12T05:50:03.667\" LastEditorUserId=\"183\" OwnerUserId=\"18\" PostTypeId=\"1\" Score=\"58\" Tags=\"&lt;software&gt;&lt;open-source&gt;\" Title=\"What are some valuable Statistical Analysis open source projects?\" ViewCount=\"4157\" />\n",
      "  \n",
      "  <row AcceptedAnswerId=\"135\" AnswerCount=\"5\" Body=\"&lt;p&gt;I have two groups of data.  Each with a different distribution of multiple variables.  I'm trying to determine if these two groups' distributions are different in a statistically significant way.  I have the data in both raw form and binned up in easier to deal with discrete categories with frequency counts in each.  &lt;/p&gt;&#10;&#10;&lt;p&gt;What tests/procedures/methods should I use to determine whether or not these two groups are significantly different and how do I do that in SAS or R (or Orange)?&lt;/p&gt;&#10;\" CommentCount=\"2\" CreationDate=\"2010-07-19T19:13:31.617\" FavoriteCount=\"3\" Id=\"4\" LastActivityDate=\"2010-09-08T03:00:19.690\" OwnerUserId=\"23\" PostTypeId=\"1\" Score=\"13\" Tags=\"&lt;distributions&gt;&lt;statistical-significance&gt;\" Title=\"Assessing the significance of differences in distributions\" ViewCount=\"7685\" />\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "testdata.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Array(\"  <row AcceptedAnswerId=\"15\" AnswerCount=\"5\" Body=\"&lt;p&gt;How should I elicit prior distributions from experts when fitting a Bayesian model?&lt;/p&gt;&#10;\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:12.510\" FavoriteCount=\"17\" Id=\"1\" LastActivityDate=\"2010-09-15T21:08:26.077\" OwnerUserId=\"8\" PostTypeId=\"1\" Score=\"26\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;\" Title=\"Eliciting priors from experts\" ViewCount=\"1457\" />\", \"  <row AcceptedAnswerId=\"59\" AnswerCount=\"7\" Body=\"&lt;p&gt;In many different statistical methods there is an &quot;assumption of normality&quot;.  What is &quot;normality&quot; and how do I know if there is normality?&lt;/p&gt;&#10;\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:57.157\" FavoriteCount=\"9\" Id=\"2\" LastActivityDate=\"2012-11-12T09:21:54.993\" LastEditDate=\"2010-08-07T17:56:44.800\" LastEditorUserId=\"88\" OwnerUserId=\"24\" PostTypeId=\"1\" Score=\"25\" Tags=\"&lt;distributions&gt;&lt;normality&gt;\" Title=\"What is normality?\" ViewCount=\"98…"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import scala.xml.XML\n",
    "//testdata.take(10).flatMap(x=>x)\n",
    "//val testd = testdata.take(10).filter(line => line.contains(\"FavoriteCount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Array(<row ViewCount=\"1457\" Title=\"Eliciting priors from experts\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;\" Score=\"26\" PostTypeId=\"1\" OwnerUserId=\"8\" LastActivityDate=\"2010-09-15T21:08:26.077\" Id=\"1\" FavoriteCount=\"17\" CreationDate=\"2010-07-19T19:12:12.510\" CommentCount=\"1\" Body=\"&lt;p&gt;How should I elicit prior distributions from experts when fitting a Bayesian model?&lt;/p&gt;\n",
       "\" AnswerCount=\"5\" AcceptedAnswerId=\"15\"/>, <row ViewCount=\"9803\" Title=\"What is normality?\" Tags=\"&lt;distributions&gt;&lt;normality&gt;\" Score=\"25\" PostTypeId=\"1\" OwnerUserId=\"24\" LastEditorUserId=\"88\" LastEditDate=\"2010-08-07T17:56:44.800\" LastActivityDate=\"2012-11-12T09:21:54.993\" Id=\"2\" FavoriteCount=\"9\" CreationDate=\"2010-07-19T19:12:57.157\" CommentCount=\"1\" Body=\"&lt;p&gt;In many different statistical methods there is an &quot;assumption of normality&quot;.  What is &quot;normality&quot; and how do I know if there is normality?&lt;/p&gt;\n",
       "\" AnswerCount=\"7\" AcceptedAnswerId=\"59\"/>, <row View…"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val testd2 = testdata.flatMap((s:String)=>{if (s.startsWith(\"  <row \") & s.endsWith(\" />\")) XML.loadString(s) else None}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "9763"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  def getInt(n: scala.xml.NodeSeq): Int = n.text match {\n",
    "    case \"\" => 0 \n",
    "    case x => x.toInt\n",
    "  }\n",
    "testd2.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "<row AcceptedAnswerId=\"15\" AnswerCount=\"5\" Body=\"&lt;p&gt;How should I elicit prior distributions from experts when fitting a Bayesian model?&lt;/p&gt;\n",
       "\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:12.510\" FavoriteCount=\"17\" Id=\"1\" LastActivityDate=\"2010-09-15T21:08:26.077\" OwnerUserId=\"8\" PostTypeId=\"1\" Score=\"26\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;\" Title=\"Eliciting priors from experts\" ViewCount=\"1457\"/>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stest = <row AcceptedAnswerId=\"15\" AnswerCount=\"5\" Body=\"&lt;p&gt;How should I elicit prior distributions from experts when fitting a Bayesian model?&lt;/p&gt;&#10;\" CommentCount=\"1\" CreationDate=\"2010-07-19T19:12:12.510\" FavoriteCount=\"17\" Id=\"1\" LastActivityDate=\"2010-09-15T21:08:26.077\" OwnerUserId=\"8\" PostTypeId=\"1\" Score=\"26\" Tags=\"&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;\" Title=\"Eliciting priors from experts\" ViewCount=\"1457\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Array(17, 9, 37, 3, 0, 155, 83, 0, 0, 16)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a= None \n",
    "//a \\ \"@FavoriteCount\"\n",
    "val b = testd2.take(10).map((x:scala.xml.Node) => getInt(x \\ \"@FavoriteCount\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Array(17, 9, 37, 3, 0, 155, 83, 0, 0, 16, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 83, 2, 0, 5, 7, 0, 0, 0, 7, 88, 0, 5, 0, 4, 25, 0, 1, 2, 0, 0, 0, 5, 0, 0, 3, 0, 0, 14, 1, 0, 26, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 17, 0, 0, 1, 0, 0, 39, 0, 0, 0, 0, 1, 0, 0, 0, 6, 22, 0, 0, 0, 0, 0, 0, 0, 23, 95, 0, 0, 4, 0, 13, 0, 0, 0, 8, 0, 0, 118, 0, 0, 0, 0, 0, 0, 3, 7, 0, 0, 0, 0, 0, 1, 0, 0, 18, 0, 0, 0, 3, 0, 0, 0, 70, 5, 0, 6, 0, 88, 0, 0, 11, 0, 27, 0, 0, 0, 0, 0, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 3, 3, 13, 0, 0, 0, 0, 0, 0, 6, 0, 2, 5, 0, 0, 0, 0, 0, 0, 48, 0, 0, 7, 0, 0, 0, 7, 0, 24, 5, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 4, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 69, 0, 0, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 6, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, …"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testd3= testd2.map((x:scala.xml.Node) => getInt(x \\ \"@FavoriteCount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<parent>\n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"1\" PostId=\"3\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"2\" PostId=\"2\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"3\" PostId=\"5\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"4\" PostId=\"5\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"5\" PostId=\"3\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"6\" PostId=\"4\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"7\" PostId=\"2\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"10\" PostId=\"3\" VoteTypeId=\"2\" />\n",
      "  \n",
      "  <row CreationDate=\"2010-07-19T00:00:00.000\" Id=\"11\" PostId=\"5\" VoteTypeId=\"2\" />\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val voltest = sc.textFile(\"./test/allVotes/part-00000.xml.gz\",minPartitions=2).cache()\n",
    "voltest.take(20).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<parent>\n",
      "  <row AboutMe=\"&lt;p&gt;Hi, I'm not really a person.&lt;/p&gt;&#10;&#10;&lt;p&gt;I'm a background process that helps keep this site clean!&lt;/p&gt;&#10;&#10;&lt;p&gt;I do things like&lt;/p&gt;&#10;&#10;&lt;ul&gt;&#10;&lt;li&gt;Randomly poke old unanswered questions every hour so they get some attention&lt;/li&gt;&#10;&lt;li&gt;Own community questions and answers so nobody gets unnecessary reputation from them&lt;/li&gt;&#10;&lt;li&gt;Own downvotes on spam/evil posts that get permanently deleted&lt;/li&gt;&#10;&lt;li&gt;Own suggested edits from anonymous users&lt;/li&gt;&#10;&lt;li&gt;&lt;a href=&quot;http://meta.stackexchange.com/a/92006&quot;&gt;Remove abandoned questions&lt;/a&gt;&lt;/li&gt;&#10;&lt;/ul&gt;&#10;\" AccountId=\"-1\" CreationDate=\"2010-07-19T06:55:26.860\" DisplayName=\"Community\" DownVotes=\"2330\" Id=\"-1\" LastAccessDate=\"2010-07-19T06:55:26.860\" Location=\"on the server farm\" Reputation=\"1\" UpVotes=\"5831\" Views=\"0\" WebsiteUrl=\"http://meta.stackexchange.com/\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;p&gt;Developer on the StackOverflow team.  Find me on&lt;/p&gt;&#10;&#10;&lt;p&gt;&lt;a href=&quot;http://www.twitter.com/SuperDalgas&quot; rel=&quot;nofollow&quot;&gt;Twitter&lt;/a&gt;&#10;&lt;br&gt;&lt;br&gt;&#10;&lt;a href=&quot;http://blog.stackoverflow.com/2009/05/welcome-stack-overflow-valued-associate-00003/&quot;&gt;Stack Overflow Valued Associate #00003&lt;/a&gt;&lt;/p&gt;&#10;\" AccountId=\"2\" Age=\"38\" CreationDate=\"2010-07-19T14:01:36.697\" DisplayName=\"Geoff Dalgas\" DownVotes=\"0\" Id=\"2\" LastAccessDate=\"2015-02-05T19:58:19.133\" Location=\"Corvallis, OR\" Reputation=\"101\" UpVotes=\"3\" Views=\"26\" WebsiteUrl=\"http://stackoverflow.com\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;p&gt;&lt;a href=&quot;http://blog.stackoverflow.com/2009/01/welcome-stack-overflow-valued-associate-00002/&quot;&gt;Developer on the Stack Overflow team&lt;/a&gt;.&lt;/p&gt;&#10;&#10;&lt;p&gt;Was dubbed &lt;strong&gt;SALTY SAILOR&lt;/strong&gt; by Jeff Atwood, as filth and flarn would oft-times fly when dealing with a particularly nasty bug!&lt;/p&gt;&#10;&#10;&lt;ul&gt;&#10;&lt;li&gt;Twitter me: &lt;a href=&quot;http://twitter.com/jarrod_dixon&quot; rel=&quot;nofollow&quot;&gt;jarrod_dixon&lt;/a&gt;&lt;/li&gt;&#10;&lt;li&gt;Email me: jarrod.m.dixon@gmail.com&lt;/li&gt;&#10;&lt;/ul&gt;&#10;\" AccountId=\"3\" Age=\"36\" CreationDate=\"2010-07-19T15:34:50.507\" DisplayName=\"Jarrod Dixon\" DownVotes=\"0\" Id=\"3\" LastAccessDate=\"2015-02-05T19:58:19.283\" Location=\"New York, NY\" Reputation=\"101\" UpVotes=\"21\" Views=\"22\" WebsiteUrl=\"http://stackoverflow.com\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;p&gt;currently at a startup in SF&lt;/p&gt;&#10;&#10;&lt;p&gt;formerly a dev at Stack Exchange :)&lt;/p&gt;&#10;\" AccountId=\"1998\" Age=\"29\" CreationDate=\"2010-07-19T19:03:27.400\" DisplayName=\"Emmett\" DownVotes=\"0\" Id=\"4\" LastAccessDate=\"2014-01-02T09:31:02.107\" Location=\"San Francisco, CA\" ProfileImageUrl=\"http://i.stack.imgur.com/d1oHX.jpg\" Reputation=\"101\" UpVotes=\"0\" Views=\"11\" WebsiteUrl=\"http://minesweeperonline.com\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;p&gt;Quantitative researcher focusing on statistics and machine learning methods in finance. Primarily use R, C++, Python, various databases (including OneTick and KDB), and LaTeX on a daily basis. &lt;/p&gt;&#10;&#10;&lt;ul&gt;&#10;&lt;li&gt;Twitter: @statalgo&lt;/li&gt;&#10;&lt;li&gt;Blog: &lt;a href=&quot;http://www.statalgo.com&quot; rel=&quot;nofollow&quot;&gt;http://www.statalgo.com&lt;/a&gt; (largely inactive)&lt;/li&gt;&#10;&lt;li&gt;Former moderator on data analysis stack exchange site: &lt;a href=&quot;http://stats.stackexchange.com/&quot;&gt;http://stats.stackexchange.com/&lt;/a&gt;&lt;/li&gt;&#10;&lt;li&gt;Proposer of Quantitative Finance stack exchange site: &lt;a href=&quot;http://area51.stackexchange.com/proposals/117/quantitative-finance?referrer=EZoOPpokWeo1&quot;&gt;http://area51.stackexchange.com/proposals/117/quantitative-finance?referrer=EZoOPpokWeo1&lt;/a&gt;&lt;/li&gt;&#10;&lt;/ul&gt;&#10;\" AccountId=\"54503\" Age=\"36\" CreationDate=\"2010-07-19T19:03:57.227\" DisplayName=\"Shane\" DownVotes=\"5\" Id=\"5\" LastAccessDate=\"2015-01-06T02:02:17.770\" Location=\"New York, NY\" Reputation=\"6962\" UpVotes=\"662\" Views=\"1206\" WebsiteUrl=\"http://www.statalgo.com\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;ul&gt;&#10;&lt;li&gt;PhD in CS/AI/Machine Learning/Cognitive Modeling from UIUC&lt;/li&gt;&#10;&lt;li&gt;Post-doctoral work in Computational Cognitive Science at Columbia, UConn, NYU&lt;/li&gt;&#10;&lt;li&gt;Statistical Data Scientist in private industry&lt;/li&gt;&#10;&lt;/ul&gt;&#10;&#10;&lt;p&gt;Twitter: @harlanh&lt;/p&gt;&#10;\" AccountId=\"46050\" Age=\"42\" CreationDate=\"2010-07-19T19:04:07.647\" DisplayName=\"Harlan\" DownVotes=\"0\" Id=\"6\" LastAccessDate=\"2014-11-21T21:36:41.787\" Location=\"District of Columbia\" Reputation=\"467\" UpVotes=\"49\" Views=\"118\" WebsiteUrl=\"http://www.harlan.harris.name\" />\n",
      "  \n",
      "  <row AboutMe=\"I'm a recent graduate of UC Davis in Economics, Political Science, and Statistics. I currently work at the Bioinformatics Core at UC Davis building web and database applications, and doing statistical programming in R.\n",
      "&#10;\n",
      "&#10;Favorites: \n",
      "&#10;Emacs, Git, C, Python, R, and any nifty open source *nix tool.\" AccountId=\"49514\" Age=\"29\" CreationDate=\"2010-07-19T19:04:37.257\" DisplayName=\"Vince\" DownVotes=\"0\" Id=\"7\" LastAccessDate=\"2015-03-04T04:42:36.000\" Location=\"Davis, CA\" Reputation=\"459\" UpVotes=\"20\" Views=\"61\" WebsiteUrl=\"http://bioinformatics.ucdavis.edu\" />\n",
      "  \n",
      "  <row AboutMe=\"&lt;p&gt;I'm a statistics lecturer at Newcastle University, UK (&lt;a href=&quot;http://www.mas.ncl.ac.uk/~ncsg3/&quot; rel=&quot;nofollow&quot;&gt;Uni homepage&lt;/a&gt;). My research interests are parallel computing, Bayesian statistics and stochastic kinetic models. &lt;/p&gt;&#10;&#10;&lt;p&gt;I also &lt;/p&gt;&#10;&#10;&lt;ul&gt;&#10;&lt;li&gt;run some &lt;a href=&quot;http://www.ncl.ac.uk/maths/rcourse/&quot; rel=&quot;nofollow&quot;&gt;R courses&lt;/a&gt; at Newcastle University&lt;/li&gt;&#10;&lt;li&gt;occasionally write the &lt;a href=&quot;http://csgillespie.wordpress.com/&quot; rel=&quot;nofollow&quot;&gt;odd blog post&lt;/a&gt;&lt;/li&gt;&#10;&lt;li&gt;run on site R training&lt;/li&gt;&#10;&lt;/ul&gt;&#10;\" AccountId=\"70002\" Age=\"37\" CreationDate=\"2010-07-19T19:04:52.280\" DisplayName=\"csgillespie\" DownVotes=\"26\" Id=\"8\" LastAccessDate=\"2015-03-04T15:50:19.397\" Location=\"Newcastle, United Kingdom\" Reputation=\"6948\" UpVotes=\"615\" Views=\"1164\" WebsiteUrl=\"http://www.mas.ncl.ac.uk/~ncsg3/\" />\n"
     ]
    }
   ],
   "source": [
    "val usertest = sc.textFile(\"./test/allUsers/part-00000.xml.gz\",minPartitions=2).cache()\n",
    "usertest.take(20).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@2c2fe834"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "java.lang.NoSuchMethodError",
     "evalue": "org.apache.spark.sql.SQLContext$implicits$.rddToDataFrameHolder(Lorg/apache/spark/rdd/RDD;Lscala/reflect/api/TypeTags$TypeTag;)Lorg/apache/spark/sql/DataFrameHolder;",
     "output_type": "error",
     "traceback": [
      "java.lang.NoSuchMethodError: org.apache.spark.sql.SQLContext$implicits$.rddToDataFrameHolder(Lorg/apache/spark/rdd/RDD;Lscala/reflect/api/TypeTags$TypeTag;)Lorg/apache/spark/sql/DataFrameHolder;"
     ]
    }
   ],
   "source": [
    "//val df1 = sc.makeRDD(1 to 5).map(i => (i, i * 2)).toDF(\"single\", \"double\")\n",
    "/*\n",
    "val sentenceDataFrame2 = sqlContext.createDataFrame(Seq(\n",
    "  (0, \"Hi I heard about Spark\"),\n",
    "  (1, \"I wish Java could use case classes\"),\n",
    "  (2, \"Logistic,regression,models,are,neat\")\n",
    ")).toDF(\"label\", \"sentence\")\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "java.lang.NoClassDefFoundError",
     "evalue": "Could not initialize class ",
     "output_type": "error",
     "traceback": [
      "java.lang.NoClassDefFoundError: Could not initialize class "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sentenceDataFrame2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.ml.feature.Tokenizer@45668245"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer().setInputCol(\"sentence\").setOutputCol(\"words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "java.lang.IllegalArgumentException",
     "evalue": "Field \"sentence\" does not exist.",
     "output_type": "error",
     "traceback": [
      "java.lang.IllegalArgumentException: Field \"sentence\" does not exist.",
      "    org.apache.spark.sql.types.StructType$$anonfun$apply$25.apply(dataTypes.scala:952)",
      "    org.apache.spark.sql.types.StructType$$anonfun$apply$25.apply(dataTypes.scala:952)",
      "    scala.collection.MapLike$class.getOrElse(MapLike.scala:128)",
      "    scala.collection.AbstractMap.getOrElse(Map.scala:58)",
      "    org.apache.spark.sql.types.StructType.apply(dataTypes.scala:951)",
      "    org.apache.spark.ml.UnaryTransformer.transformSchema(Transformer.scala:87)",
      "    org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:50)",
      "    org.apache.spark.ml.UnaryTransformer.transform(Transformer.scala:98)",
      "    org.apache.spark.ml.Transformer.transform(Transformer.scala:46)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val tokenized = tokenizer.transform(sentenceDataFrame2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.3 (Scala 2.10)",
   "language": "scala",
   "name": "spark-1.3-scala-2.10"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
