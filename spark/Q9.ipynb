{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to load in the data into dataframe\n",
    "# load the top tag for training\n",
    "# split the dataframe\n",
    "#for each tags\n",
    "    # for the training sets,label and train a model\n",
    "    # for testing sets, do a prediction, write the result to list\n",
    "#dill\n",
    "\n",
    "# load file\n",
    "import htmltagfilter\n",
    "#import pandas as pd\n",
    "\n",
    "rawdatadir = './result4/'\n",
    "labelvec = list()\n",
    "textvec = list()\n",
    "abnormal = list()\n",
    "for i in xrange(11):\n",
    "    if i<10:\n",
    "        filename = rawdatadir+'part-0000'+str(i)\n",
    "    else:\n",
    "        filename = rawdatadir+'part-000'+str(i)\n",
    "    with open(filename,'rb') as f:\n",
    "        temptext = f.read().split(\",cyx0723recordend\")\n",
    "        for line in temptext:\n",
    "            tl = line.split(',cyx0723,')\n",
    "            try:\n",
    "                textvec.append(htmltagfilter.filter_tags(tl[2]))\n",
    "                labelvec.append(tl[0].split(','))\n",
    "            except:\n",
    "                abnormal.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine-learning', 'cross-validation']\n",
      "I'm having trouble with a basic machine learning methodology question. I understand the concept of not using the same data to both train and evaluate a classifier, and furthermore when there are parameters in an algorithm to be optimized, you should use an independent third test set to get the final reportable performance figures (e.g. recall rate). However, using a single test set to measure performance seems to be problematic because the measures of performance will likely differ depending on how the data is partitioned into training (plus validation) and test sets, especially for small datasets. It would be better to average the results of N different partitions.\n",
      "For the training stage, this is exactly why people normally use k-fold cross-validation, but if you were to repeat the final test stage with different test sets (i.e. k-fold cross validation), then you are mixing data used for parameter tuning with the test data. This is what all the machine learning references I've seen say not to do. But how to get a good performance measure that is not dependent on partitioning of the data set?\n",
      "EDITED\n",
      "Related to cbeleites's comment:\n",
      "I'm not sure whether or not I understand the concept of nested cross validation. Here is a check of my understanding. Please comment if I am not correct. Assume I have 1200 labeled samples, and I want to compare 3 different models (e.g. a decision tree algorithm with three different parameter settings). For each model, I would have two cross-validation loops--an outer loop that performs testing and an inner loop that generates the model and also tests it. For the \"outer\" loop, if I were to choose 4-fold I first make a 75/25 split to create a training/validation set (900 samples) and test set (300 samples). With the 75% portion, I perform k-fold cross validation (in my example below I choose 3-fold, in order to keep the figure simple, so there are 300 samples per fold) and calculate the average performance of the k-folds. I would then re-train the same model (i.e. same parameter settings) using the full 75% portion and then test with the remaining 25%.\n",
      "I would then repeat this procedure three times using different folds from the outer loop (see figure). The final part is where I'm a bit unsure what is the right procedure. Do I average the four tests from each model (i.e. the folds from the outer loop). What actually is the purpose then of the inner loop? Or am I not doing the nesting correctly at all?\n",
      "\n",
      "52060\n",
      "['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print labelvec[0]\n",
    "print textvec[0]\n",
    "print len(labelvec)\n",
    "print abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toptag = list()\n",
    "with open('toptag.txt','rb') as f:\n",
    "    for line in f:\n",
    "        toptag.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "time-series\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print len(toptag)\n",
    "print toptag[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "estimator = TfidfVectorizer(min_df=0.01)\n",
    "estimator.fit(textvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load train and test data\n",
    "rawtraindir = './result5/train/'\n",
    "labeltr = list()\n",
    "texttr = list()\n",
    "abnormaltr = list()\n",
    "for i in xrange(11):\n",
    "    if i<10:\n",
    "        filename = rawtraindir+'part-0000'+str(i)\n",
    "    else:\n",
    "        filename = rawtraindir+'part-000'+str(i)\n",
    "    with open(filename,'rb') as f:\n",
    "        temptext = f.read().split(\",cyx0723recordend\")\n",
    "        for line in temptext:\n",
    "            tl = line.split(',cyx0723,')\n",
    "            try:\n",
    "                texttr.append(htmltagfilter.filter_tags(tl[2]))\n",
    "                labeltr.append(tl[0].split(','))\n",
    "            except:\n",
    "                abnormaltr.append(line)\n",
    "\n",
    "                \n",
    "rawtestdir = './result5/test/'\n",
    "labelte = list()\n",
    "textte = list()\n",
    "abnormaltr = list()\n",
    "for i in xrange(11):\n",
    "    if i<10:\n",
    "        filename = rawtestdir+'part-0000'+str(i)\n",
    "    else:\n",
    "        filename = rawtestdir+'part-000'+str(i)\n",
    "    with open(filename,'rb') as f:\n",
    "        temptext = f.read().split(\",cyx0723recordend\")\n",
    "        for line in temptext:\n",
    "            tl = line.split(',cyx0723,')\n",
    "            try:\n",
    "                textte.append(htmltagfilter.filter_tags(tl[2]))\n",
    "                labelte.append(tl[0].split(','))\n",
    "            except:\n",
    "                abnormaltr.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5212\n"
     ]
    }
   ],
   "source": [
    "print len(labelte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the neccesary library:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# now we try to train 100 binary lr model\n",
    "# first we try to transform the original \n",
    "Xtrain = estimator.transform(texttr)\n",
    "Xtest = estimator.transform(textte)\n",
    "count = 0\n",
    "#then for all the model, we have different training label\n",
    "#we need to generate it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean the labelsets\n",
    "ytr = list()\n",
    "for i in labeltr:\n",
    "    temprow = [i[0].replace('\\n','')]\n",
    "    temprow.extend(i[1:])\n",
    "    ytr.append(temprow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r', 'machine-learning', 'python', 'matrix', 'information-retrieval']\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "print ytr[1]\n",
    "a = toptag[0].replace('\\n','')\n",
    "if a in ytr[1]:\n",
    "    print 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "allresult = list()\n",
    "for tt in toptag:\n",
    "    tag = tt.replace('\\n','')\n",
    "    lrmodel = LogisticRegression()\n",
    "    ycurrent = list()\n",
    "    for i in ytr:\n",
    "        if tag in i:\n",
    "            ycurrent.append(1)\n",
    "        else:\n",
    "            ycurrent.append(0)\n",
    "        #now we start to train the model\n",
    "    lrmodel.fit(Xtrain,ycurrent)\n",
    "    tempresult = lrmodel.predict_proba(Xtest)\n",
    "    allresult.append((tag,tempresult[:,1].tolist()[91:]))\n",
    "    count+=1\n",
    "    if count%10==0:\n",
    "        print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(allresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5121\n"
     ]
    }
   ],
   "source": [
    "print len(allresult[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as cp\n",
    "with open('q9result.data','wb') as f:\n",
    "    cp.dump(allresult,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "rs = cross_validation.ShuffleSplit(52060, n_iter=10,test_size=.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n",
      "5206\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in rs:\n",
    "    print len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5206\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
