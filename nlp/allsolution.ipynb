{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, ujson, random\n",
    "import toolz\n",
    "import cPickle as c\n",
    "import nltk.tokenize\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def getjsontext(d):\n",
    "    return [toolz.keyfilter(lambda k: k == \"text\", d)]\n",
    "\n",
    "def load_json_yelp(filepath):\n",
    "    data=dict()\n",
    "    data['text']=list()\n",
    "    data['stars']=list()\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        for line in f:\n",
    "            pick = random.randint(0,99) \n",
    "            if pick==0: #try to reduce the number of sample by randomly picking 5% of all data\n",
    "                temp = ujson.loads(line)\n",
    "                #data['text'].append(toolz.keyfilter(lambda k: k == \"text\", line))\n",
    "                data['text'].append(temp['text'].encode('utf-8'))\n",
    "                data['stars'].append(temp['stars'])\n",
    "    return data\n",
    "\n",
    "def tokenizereview(str):\n",
    "    return nltk.tokenize.sent_tokenize(str)\n",
    "\n",
    "#data loading\n",
    "filepath = 'yelp_train_academic_dataset_review.json.gz'\n",
    "yelp_data = load_json_yelp(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10103\n",
      "10103\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "print len(yelp_data['text'])\n",
    "print len(yelp_data['stars'])\n",
    "#testvec = CountVectorizer()\n",
    "#X_ct = testvec.fit_transform(yelp_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for problem one\n",
    "#the place for class definition\n",
    "class  Q1Estimator(sk.base.BaseEstimator, sk.base.RegressorMixin):\n",
    "    def __init__(self,model):\n",
    "        self.est = model\n",
    "        pass\n",
    "    def fit(self,X,y):\n",
    "        test_param = {'alpha':[1,3,5,7,9,10]}\n",
    "        gscv = GridSearchCV(self.est, test_param)\n",
    "        gscv.fit(X,y)\n",
    "        self.est = gscv.best_estimator_\n",
    "        print gscv.best_params_ \n",
    "        #self.est.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        return self.est.score(X,y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.est.predict(X)\n",
    "    \n",
    "\n",
    "class Q1Transformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        #self.vectorizer = CountVectorizer(max_df=0.99, min_df=0.01,stop_words=nltk.corpus.stopwords.words('english'))\n",
    "        #self.vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'))\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        X=map(lambda x:x.lower(),X)\n",
    "        self.vectorizer.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        X=map(lambda x:x.decode('utf-8').encode('utf-8').lower(),X)\n",
    "        X_trans = self.vectorizer.transform(X)\n",
    "        return X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vectorize',Q1Transformer()),('estimate',Q1Estimator(linear_model.Ridge()))])\n",
    "X=yelp_data['text']\n",
    "y=yelp_data['stars']\n",
    "presult = pipeline.fit(X,y)\n",
    "\n",
    "with open('bow_model','wb') as output:\n",
    "    dill.dump(presult,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorize', Q1Transformer()), ('estimate', Q1Estimator(model=None))])\n",
      "0.718139232354\n"
     ]
    }
   ],
   "source": [
    "with open('bow_model','rb') as instrm:\n",
    "    datastruct = dill.load(instrm)\n",
    "print datastruct\n",
    "\n",
    "presult = datastruct.predict(X)\n",
    "\n",
    "print datastruct.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for problem two\n",
    "#the place for class definition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class  NormalEstimator(sk.base.BaseEstimator, sk.base.RegressorMixin):\n",
    "    def __init__(self,model):\n",
    "        self.est = model\n",
    "        pass\n",
    "    def fit(self,X,y):\n",
    "        test_param = {'alpha':[0.01,0.05,0.1,0.3,0.5,1,10]}\n",
    "        gscv = GridSearchCV(self.est, test_param)\n",
    "        gscv.fit(X,y)\n",
    "        self.est = gscv.best_estimator_\n",
    "        print gscv.best_params_ \n",
    "        #self.est.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        return self.est.score(X,y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.est.predict(X)\n",
    "    \n",
    "\n",
    "class NormalTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        #self.vectorizer = TfidfVectorizer(max_df=0.99, min_df=0.01,stop_words=nltk.corpus.stopwords.words('english'))\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=nltk.corpus.stopwords.words('english'))\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        X = map(lambda x:x.lower(),X)\n",
    "        self.vectorizer.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        if type(X) == dict:\n",
    "            X['text'].lower()\n",
    "            X_trans = self.vectorizer.transform(X['text'])\n",
    "        else:\n",
    "            X=map(lambda x:x.lower(),X)\n",
    "            X_trans = self.vectorizer.transform(X)\n",
    "        return X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vectorize2',NormalTransformer()),('estimate2',NormalEstimator(linear_model.Ridge()))])\n",
    "X=yelp_data['text']\n",
    "y=yelp_data['stars']\n",
    "presult = pipeline.fit(X,y)\n",
    "\n",
    "with open('tfidf_model','wb') as output:\n",
    "    dill.dump(presult,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorize2', NormalTransformer()), ('estimate2', NormalEstimator(model=None))])\n",
      "0.760428898228\n"
     ]
    }
   ],
   "source": [
    "with open('tfidf_model','rb') as instrm:\n",
    "    datastruct2 = dill.load(instrm)\n",
    "print datastruct2\n",
    "\n",
    "presult = datastruct2.predict(X)\n",
    "\n",
    "print datastruct2.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
